def get_transforms():
    {% if config.mainDataType == "Image Data" %}
    transform = transforms.Compose([
    {% if config.preprocessing and config.preprocessing|length > 0 %}
    {% for p in config.preprocessing %}
        {{ p }},
    {% endfor %}
    {% else %}
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    {% endif %}
    ])
    return transform
    {% elif config.mainDataType == "Text Data" %}
    # Text transformations
    # TODO: Implement text-specific transformations
    return None
    {% elif config.mainDataType == "Audio Data" %}
    # Audio transformations
    transform = nn.Sequential(
    {% if config.preprocessing and config.preprocessing|length > 0 %}
    {% for p in config.preprocessing %}
        {{ p }},
    {% endfor %}
    {% else %}
        audio_transforms.MelSpectrogram(sample_rate=16000, n_mels=64),
        audio_transforms.AmplitudeToDB(),
    {% endif %}
    )
    return transform
    {% else %}
    # Generic transformations
    # TODO: Implement data-specific transformations
    return None
    {% endif %}

# Create data loaders

def create_data_loaders(data_path, batch_size={{ config.training.batchSize or 32 }}, train_ratio=0.8):
    transform = get_transforms()
    dataset = CustomDataset(data_path, transform=transform)
    train_size = int(train_ratio * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)
    return train_loader, val_loader
